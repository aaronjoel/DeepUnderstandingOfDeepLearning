{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMkIDAzfsG9fM60pPU3NBM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6fa9c85422a64c82a05163892d8972cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5c9318cf2414fdca829f245d560c615",
              "IPY_MODEL_5a354242f4614c0097dad09c9d0e9137",
              "IPY_MODEL_25ef3b117938432fbe8cbfa49c1b5fba"
            ],
            "layout": "IPY_MODEL_efd60339c7c44bd6910f5b7c05361bd9"
          }
        },
        "e5c9318cf2414fdca829f245d560c615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14695b28db4a4302904939c6d74a0062",
            "placeholder": "​",
            "style": "IPY_MODEL_9f921784fa2541d991e1849b50ae5b53",
            "value": "Epoch 39: 100%"
          }
        },
        "5a354242f4614c0097dad09c9d0e9137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61649a9e82934e08af7e574cd8c7443f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5952e04926484def94d1bddc00ff025e",
            "value": 2
          }
        },
        "25ef3b117938432fbe8cbfa49c1b5fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53c450aa94de496f8dad03a1b06bae6e",
            "placeholder": "​",
            "style": "IPY_MODEL_3813419db4a1419182995309bd412442",
            "value": " 2/2 [00:00&lt;00:00, 42.09it/s, v_num=0]"
          }
        },
        "efd60339c7c44bd6910f5b7c05361bd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "14695b28db4a4302904939c6d74a0062": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f921784fa2541d991e1849b50ae5b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61649a9e82934e08af7e574cd8c7443f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5952e04926484def94d1bddc00ff025e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53c450aa94de496f8dad03a1b06bae6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3813419db4a1419182995309bd412442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaronjoel/DeepUnderstandingOfDeepLearning/blob/main/chapter_10_seq2seq_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The StatQuest Illustrated Guide to Neural Networks and AI\n",
        "\n",
        "## Chapter 10 - Seq2Seq and Encoder-Decoder Models with LSTMs\n",
        "\n",
        "Copyright 2024, Joshua Starmer"
      ],
      "metadata": {
        "id": "tZL602qHULW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will build and train a Seq2Seq or Encoder-Decoder model with 2 layers of LSTMs, each layer with 2 stacks of LSTMs as seen in the picture below."
      ],
      "metadata": {
        "id": "h2riZTcAUMlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install lightning"
      ],
      "metadata": {
        "id": "nkC89RzFUkDI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import lightning as L"
      ],
      "metadata": {
        "id": "IIHEhqGCVEVx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the datasets that we will use for training Encoder-Decoder model\n",
        "\n",
        "To make the model at least a little bit interesting, we will translate two english phrases, **Let's go** and **to go** into spanish. **Let's go** should translate to **vamos \\<EOS\\>** and **to go** should translate to **ir \\<EOS\\>**."
      ],
      "metadata": {
        "id": "HqYfSjClVuOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first, we create a dictionary that maps vocabulary tokens to id numbers...\n",
        "english_token_to_id = {\n",
        "    'lets': 0,\n",
        "    'to': 1,\n",
        "    'go': 2,\n",
        "    '<EOS>': 3  ### <EOS> = end of sequence\n",
        "}\n",
        "print(english_token_to_id)\n",
        "\n",
        "## ...then we create a dictionary that maps the ids to tokens. This will help us interpret the output.\n",
        "## We use the \"map()\" function to apply the \"reversed()\" function to each tuple (i.e. ('lets', 0)) stored\n",
        "## in the token_to_id dictionary. We then use dict() to make a new dictionary from the\n",
        "## reversed tuples.\n",
        "english_id_to_token = dict(map(reversed, english_token_to_id.items()))\n",
        "print(english_id_to_token)\n",
        "\n",
        "spanish_token_to_id = {\n",
        "    'ir': 0,\n",
        "    'vamos': 1,\n",
        "    'y': 2,\n",
        "    '<EOS>': 3\n",
        "}\n",
        "\n",
        "print(spanish_token_to_id)\n",
        "\n",
        "spanish_id_to_token = dict(map(reversed, spanish_token_to_id.items()))\n",
        "print(spanish_id_to_token)\n",
        "\n",
        "inputs = torch.tensor([[english_token_to_id['lets'],\n",
        "                        english_token_to_id['go']],\n",
        "\n",
        "                       [english_token_to_id['to'],\n",
        "                       english_token_to_id['go']]])\n",
        "\n",
        "labels = torch.tensor([[spanish_token_to_id['vamos'],\n",
        "                        spanish_token_to_id['<EOS>']],\n",
        "\n",
        "                       [spanish_token_to_id['ir'],\n",
        "                       spanish_token_to_id['<EOS>']]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PgAkN63Vshx",
        "outputId": "a7095210-68d2-49c9-db7d-5b6648ada274"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'lets': 0, 'to': 1, 'go': 2, '<EOS>': 3}\n",
            "{0: 'lets', 1: 'to', 2: 'go', 3: '<EOS>'}\n",
            "{'ir': 0, 'vamos': 1, 'y': 2, '<EOS>': 3}\n",
            "{0: 'ir', 1: 'vamos', 2: 'y', 3: '<EOS>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have created the data that we want to train the embeddings with we'll store it in a `DataLoader`. Since our dataset is so small, using a `DataLoader` is a little bit of an overkill, but it is easy to do, and it will allow us to easily scale up to a much larger vocabulary when the time comes."
      ],
      "metadata": {
        "id": "ZAaX9t17aWpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(inputs, labels)\n",
        "dataloader = DataLoader(dataset)"
      ],
      "metadata": {
        "id": "BeJ47A-vW3Xq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class seq2seq(L.LightningModule):\n",
        "\n",
        "    def __init__(self, max_len=2):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.max_output_length = max_len\n",
        "\n",
        "        L.seed_everything(seed=420)\n",
        "\n",
        "        #################################\n",
        "        ##\n",
        "        ## ENCODING\n",
        "        ##\n",
        "        #################################\n",
        "        self.encoder_we = nn.Embedding(num_embeddings=4, # num_embeddings = # of words in input vocabulary\n",
        "                                       embedding_dim=2)  # embedding_dim = 2 numbers per embedding\n",
        "\n",
        "        self.encoder_lstm = nn.LSTM(input_size=2, # input_size = number of inputs (2 numbers per word)\n",
        "                                    hidden_size=2,# hidden_size = number of outputs (2 per word per layer)\n",
        "                                    num_layers=2) # num_layers = how many lstm's to stack\n",
        "                                                  #          If there are 2 layers, then the short term memory from the\n",
        "                                                  #          first layer is used as input to the second layer\n",
        "\n",
        "        #################################\n",
        "        ##\n",
        "        ## DECODING\n",
        "        ##\n",
        "        #################################\n",
        "        self.decoder_we = nn.Embedding(num_embeddings=4,\n",
        "                                       embedding_dim=2)\n",
        "\n",
        "        self.decoder_lstm = nn.LSTM(input_size=2,\n",
        "                                    hidden_size=2,\n",
        "                                    num_layers=2)\n",
        "\n",
        "        self.output_fc = nn.Linear(in_features=2,  # in_features = # of outputs per LSTM\n",
        "                                   out_features=4) # out_features = # of words in the output vocabulary\n",
        "\n",
        "        #################################\n",
        "        ##\n",
        "        ## Training\n",
        "        ##\n",
        "        #################################\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    def forward(self, input, output=None):\n",
        "\n",
        "        #################################\n",
        "        ##\n",
        "        ## ENCODING\n",
        "        ##\n",
        "        #################################\n",
        "        ## first, use the encoder stage to create an intermediate encoding of the input text\n",
        "        encoder_embeddings = self.encoder_we(input)\n",
        "        encoder_lstm_output, (encoder_lstm_hidden, encoder_lstm_cell) = self.encoder_lstm(encoder_embeddings)\n",
        "\n",
        "        #################################\n",
        "        ##\n",
        "        ## DECODING\n",
        "        ##\n",
        "        #################################\n",
        "        ## We start by initializing the decoder with the <EOS> token...\n",
        "        decoder_token_id = torch.tensor([spanish_token_to_id[\"<EOS>\"]])\n",
        "        decoder_embeddings = self.decoder_we(decoder_token_id)\n",
        "\n",
        "        decoder_lstm_output, (decoder_lstm_hidden, decoder_lstm_cell) = self.decoder_lstm(decoder_embeddings,\n",
        "                                                                                          (encoder_lstm_hidden,\n",
        "                                                                                           encoder_lstm_cell))\n",
        "\n",
        "        output_values = self.output_fc(decoder_lstm_output)\n",
        "        outputs = output_values\n",
        "\n",
        "        predicted_id = torch.tensor([torch.argmax(output_values)])\n",
        "        predicted_ids = predicted_id\n",
        "\n",
        "        for i in range(1, self.max_output_length):\n",
        "\n",
        "            if (output == None): # using the model...\n",
        "                if (predicted_id == spanish_token_to_id[\"<EOS>\"]): # if the prediction is <EOS>, then we are done\n",
        "                    break\n",
        "                decoder_embeddings = self.decoder_we(predicted_id)\n",
        "            else:\n",
        "                ## run this when training the model\n",
        "                decoder_embeddings = self.decoder_we(torch.tensor([output[i-1]]))\n",
        "\n",
        "            decoder_lstm_output, (decoder_lstm_hidden, decoder_lstm_cell) = self.decoder_lstm(decoder_embeddings,\n",
        "                                                                                              (decoder_lstm_hidden,\n",
        "                                                                                               decoder_lstm_cell))\n",
        "\n",
        "            output_values = self.output_fc(decoder_lstm_output)\n",
        "            outputs = torch.cat((outputs, output_values), 0)\n",
        "            predicted_id = torch.tensor([torch.argmax(output_values)])\n",
        "            predicted_ids = torch.cat((predicted_ids, predicted_id))\n",
        "\n",
        "        return(outputs)\n",
        "\n",
        "\n",
        "    def configure_optimizers(self): # this configures the optimizer we want to use for backpropagation.\n",
        "        return Adam(self.parameters(), lr=0.1) ## NOTE: Setting the learning rate to 0.1 trains way faster than\n",
        "                                               ## using the default learning rate, lr=0.001\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx): # take a step during gradient descent.\n",
        "        input_tokens, labels = batch # collect input\n",
        "        output = self.forward(input_tokens[0], labels[0]) # run input through the neural network\n",
        "        loss = self.loss(output, labels[0]) ## self.loss = cross entropy\n",
        "        ###################\n",
        "        ##\n",
        "        ## Logging the loss\n",
        "        ##\n",
        "        ###################\n",
        "        # self.log(\"train_loss\", loss)\n",
        "\n",
        "        return loss\n",
        ""
      ],
      "metadata": {
        "id": "t6qdnLS3hZvM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = seq2seq()\n",
        "outputs = model.forward(input=torch.tensor([english_token_to_id[\"lets\"],\n",
        "                                            english_token_to_id[\"go\"]]), ## translate \"lets go\", we should get \"vamos <EOS>\"\n",
        "                        output=None)\n",
        "\n",
        "print(\"Translated text:\")\n",
        "predicted_ids = torch.argmax(outputs, dim=1)\n",
        "for id in predicted_ids:\n",
        "    print(\"\\t\", spanish_id_to_token[id.item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcEG5PYKjiWM",
        "outputId": "8c3c2420-5104-4925-a837-feb063231b05"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Seed set to 420\n",
            "INFO:lightning.fabric.utilities.seed:Seed set to 420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated text:\n",
            "\t <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = L.Trainer(max_epochs=40, accelerator='cpu')\n",
        "trainer.fit(model, train_dataloaders=dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815,
          "referenced_widgets": [
            "6fa9c85422a64c82a05163892d8972cc",
            "e5c9318cf2414fdca829f245d560c615",
            "5a354242f4614c0097dad09c9d0e9137",
            "25ef3b117938432fbe8cbfa49c1b5fba",
            "efd60339c7c44bd6910f5b7c05361bd9",
            "14695b28db4a4302904939c6d74a0062",
            "9f921784fa2541d991e1849b50ae5b53",
            "61649a9e82934e08af7e574cd8c7443f",
            "5952e04926484def94d1bddc00ff025e",
            "53c450aa94de496f8dad03a1b06bae6e",
            "3813419db4a1419182995309bd412442"
          ]
        },
        "id": "n92hDS1ljsBx",
        "outputId": "ff1fdd3c-7692-428d-b57e-4d691a04356d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
            "INFO: GPU available: False, used: False\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO: \n",
            "  | Name         | Type             | Params | Mode \n",
            "----------------------------------------------------------\n",
            "0 | encoder_we   | Embedding        | 8      | train\n",
            "1 | encoder_lstm | LSTM             | 96     | train\n",
            "2 | decoder_we   | Embedding        | 8      | train\n",
            "3 | decoder_lstm | LSTM             | 96     | train\n",
            "4 | output_fc    | Linear           | 12     | train\n",
            "5 | loss         | CrossEntropyLoss | 0      | train\n",
            "----------------------------------------------------------\n",
            "220       Trainable params\n",
            "0         Non-trainable params\n",
            "220       Total params\n",
            "0.001     Total estimated model params size (MB)\n",
            "6         Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name         | Type             | Params | Mode \n",
            "----------------------------------------------------------\n",
            "0 | encoder_we   | Embedding        | 8      | train\n",
            "1 | encoder_lstm | LSTM             | 96     | train\n",
            "2 | decoder_we   | Embedding        | 8      | train\n",
            "3 | decoder_lstm | LSTM             | 96     | train\n",
            "4 | output_fc    | Linear           | 12     | train\n",
            "5 | loss         | CrossEntropyLoss | 0      | train\n",
            "----------------------------------------------------------\n",
            "220       Trainable params\n",
            "0         Non-trainable params\n",
            "220       Total params\n",
            "0.001     Total estimated model params size (MB)\n",
            "6         Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fa9c85422a64c82a05163892d8972cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: `Trainer.fit` stopped: `max_epochs=40` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=40` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.forward(input=torch.tensor([english_token_to_id[\"lets\"],\n",
        "                                            english_token_to_id[\"go\"]]), ## translate \"lets go\", we should get \"vamos <EOS>\"\n",
        "                        output=None)\n",
        "\n",
        "print(\"Translated text:\")\n",
        "predicted_ids = torch.argmax(outputs, dim=1)\n",
        "for id in predicted_ids:\n",
        "    print(\"\\t\", spanish_id_to_token[id.item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0BZ-atLj5ms",
        "outputId": "6bcc1310-964a-4d22-e0c3-a85f9ae1b557"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated text:\n",
            "\t vamos\n",
            "\t <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.forward(input=torch.tensor([english_token_to_id[\"to\"],\n",
        "                                            english_token_to_id[\"go\"]]), ## translate \"lets go\", we should get \"vamos <EOS>\"\n",
        "                        output=None)\n",
        "\n",
        "print(\"Translated text:\")\n",
        "predicted_ids = torch.argmax(outputs, dim=1)\n",
        "for id in predicted_ids:\n",
        "    print(\"\\t\", spanish_id_to_token[id.item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORl8wqD-j-v5",
        "outputId": "df0870ec-d2bc-413b-9e80-364c973c8681"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated text:\n",
            "\t ir\n",
            "\t <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## count the number of parameters...\n",
        "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"Total number of trainable parameters:\", total_trainable_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdHIQHCFkIIq",
        "outputId": "45faecf9-e44d-431f-9542-5c596af38dd6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable parameters: 220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## First, save the weights...\n",
        "trainer.save_checkpoint(\"seq2seq_en2es_220_trained.ckpt\") ## NOTE: You can specify a path as part of the filename"
      ],
      "metadata": {
        "id": "sSjmGcLhkPmG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Now let's create a new model and load in the saved weights...\n",
        "new_model = seq2seq.load_from_checkpoint(\"seq2seq_en2es_220_trained.ckpt\")\n",
        "\n",
        "outputs = new_model.forward(input=torch.tensor([english_token_to_id[\"lets\"],\n",
        "                                                english_token_to_id[\"go\"]]),\n",
        "                            output=None)\n",
        "\n",
        "print(\"Translated text:\")\n",
        "predicted_ids = torch.argmax(outputs, dim=1)\n",
        "for id in predicted_ids:\n",
        "    print(\"\\t\", spanish_id_to_token[id.item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjV70KjAkaZ9",
        "outputId": "d63711f4-a621-4b51-b7a0-abf14d8b1fa5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Seed set to 420\n",
            "INFO:lightning.fabric.utilities.seed:Seed set to 420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated text:\n",
            "\t vamos\n",
            "\t <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XMOnNc5hkc96"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}